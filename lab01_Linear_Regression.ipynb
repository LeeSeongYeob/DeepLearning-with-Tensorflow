{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab01_Linear_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og5QYLCU7pHk",
        "colab_type": "text"
      },
      "source": [
        "구현해볼 내용\n",
        "공부 시간에 따른 성적 예측 모델\n",
        "$$ H(x) = Wx + b $$\n",
        "$$ cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2 $$\n",
        "- H(x)$: 주어진 $x$ 값에 대해 예측을 어떻게 할 것인가  \n",
        "\n",
        "- cost(W, b)$: $H(x)$ 가 $y$ 를 얼마나 잘 예측했는가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VfYg9n_1bBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03Ot7AHt8DQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 X,Y 선언부분\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erIQgejO9D84",
        "colab_type": "text"
      },
      "source": [
        "##weight 와 bias 초기화 부분.\n",
        "- 0으로 초기화 시킴\n",
        "- requires_grad 옵션 -> Ture 설정 시, 학습할 것이라고 명시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ozkBkKU9Cqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weight 와 bias 초기화 부분.\n",
        "W = torch.zeros(1,requires_grad=True)\n",
        "b = torch.zeros(1,requires_grad=True)\n",
        "\n",
        "# 가설 설정 \n",
        "hypothesis = x_train * W + b"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbT1-xsL9VVC",
        "colab_type": "text"
      },
      "source": [
        "Cost\n",
        "$$ cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2 $$\n",
        "Mean Square Error(MSE) 라고 함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSgbduYq9TZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cost function\n",
        "cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "# optimizer 선언부. \n",
        "# W,b 는 학습할 tensor 들,  ir -> learning rate 를 의마함\n",
        "optimizer = optim.SGD([W,b],lr= 0.01)\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        " # cost function\n",
        "cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "optimizer.zero_grad()       # grad 초기화\n",
        "cost.backward()             # grad 계산\n",
        "optimizer.step()            # grad 적용 및 개선"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx__62ztAHFp",
        "colab_type": "text"
      },
      "source": [
        "# 코드 전체 학습 부분"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8_hucUiAGa4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "a99ae6cb-92d9-4293-f9cf-0a73eb0598d8"
      },
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "epochs = 1000\n",
        "for epoch in range(epochs + 1):\n",
        "    \n",
        "    # H(x) 계산\n",
        "    hypothesis = x_train * W + b\n",
        "    \n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, epochs, W.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 W: 0.093, b: 0.040 Cost: 4.666667\n",
            "Epoch  100/1000 W: 0.873, b: 0.289 Cost: 0.012043\n",
            "Epoch  200/1000 W: 0.900, b: 0.227 Cost: 0.007442\n",
            "Epoch  300/1000 W: 0.921, b: 0.179 Cost: 0.004598\n",
            "Epoch  400/1000 W: 0.938, b: 0.140 Cost: 0.002842\n",
            "Epoch  500/1000 W: 0.951, b: 0.110 Cost: 0.001756\n",
            "Epoch  600/1000 W: 0.962, b: 0.087 Cost: 0.001085\n",
            "Epoch  700/1000 W: 0.970, b: 0.068 Cost: 0.000670\n",
            "Epoch  800/1000 W: 0.976, b: 0.054 Cost: 0.000414\n",
            "Epoch  900/1000 W: 0.981, b: 0.042 Cost: 0.000256\n",
            "Epoch 1000/1000 W: 0.985, b: 0.033 Cost: 0.000158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8Zuss-tBNCy",
        "colab_type": "text"
      },
      "source": [
        "#nn.module 사용하기\n",
        "**pytorh 에서 사용하는 모델은 nn.Module을 상속하여 만든다.**\n",
        "- 모델의 __init__에서는 사용할 레이어들을 정의\n",
        "- forward 는 어떻게 입력값에서 출력값을 계산하는지 알려줌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cCI1hMnBMhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix8ICOvoBxpt",
        "colab_type": "text"
      },
      "source": [
        "# 전체 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7758ONHbBw27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "ec468845-f9f2-43e1-9ae9-0d94c82d2a49"
      },
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "# 모델 초기화\n",
        "model = LinearRegressionModel()\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    \n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "    \n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "    \n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        params = list(model.parameters())\n",
        "        W = params[0].item()\n",
        "        b = params[1].item()\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W, b, cost.item()\n",
        "        ))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 W: 0.222, b: -0.137 Cost: 4.131519\n",
            "Epoch  100/1000 W: 0.941, b: 0.135 Cost: 0.002626\n",
            "Epoch  200/1000 W: 0.953, b: 0.106 Cost: 0.001623\n",
            "Epoch  300/1000 W: 0.963, b: 0.083 Cost: 0.001003\n",
            "Epoch  400/1000 W: 0.971, b: 0.066 Cost: 0.000620\n",
            "Epoch  500/1000 W: 0.977, b: 0.052 Cost: 0.000383\n",
            "Epoch  600/1000 W: 0.982, b: 0.041 Cost: 0.000237\n",
            "Epoch  700/1000 W: 0.986, b: 0.032 Cost: 0.000146\n",
            "Epoch  800/1000 W: 0.989, b: 0.025 Cost: 0.000090\n",
            "Epoch  900/1000 W: 0.991, b: 0.020 Cost: 0.000056\n",
            "Epoch 1000/1000 W: 0.993, b: 0.015 Cost: 0.000034\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}