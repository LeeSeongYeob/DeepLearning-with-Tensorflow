{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab03_Multivariate_Linear_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwHCEGC4Vkpc",
        "colab_type": "text"
      },
      "source": [
        "# Multivariate Linear Regression\n",
        "- Matrix Data\n",
        "- Use nn.Module\n",
        "- Mini-Batch GD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L00q2ygaNvsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import handcalcs.render"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ1tPdsqV4Ec",
        "colab_type": "text"
      },
      "source": [
        "## Matrix data\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "x_1  x_2  x_3\n",
        "\\end{pmatrix}\n",
        "\\cdot\n",
        "\\begin{pmatrix}\n",
        "w_1 \\\\\n",
        "w_2 \\\\\n",
        "w_3 \\\\\n",
        "\\end{pmatrix}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "x_1w_1 + x_2w_2 + x_3w_3\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "$$ H(X) = XW $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA_Q4HKRTs1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3d92277-152a-46f9-8f3a-a7f3ffa156aa"
      },
      "source": [
        "# data set\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3]) torch.Size([5, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf-T-6VkWKMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "97f2bca1-503b-4777-81ad-c644b7e47722"
      },
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((3,1), requires_grad=True)\n",
        "b = torch.zeros(1,requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr = 1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    \n",
        "    # H(x) 계산\n",
        "    hypo = x_train.matmul(W) + b\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypo - y_train)**2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(\"Epoch {:4d}/{} H: {} Cost: {:.6f}\".format(epoch,nb_epochs,hypo.squeeze().detach(),cost.item()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/20 H: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch    1/20 H: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]) Cost: 9298.520508\n",
            "Epoch    2/20 H: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]) Cost: 2915.712402\n",
            "Epoch    3/20 H: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]) Cost: 915.040527\n",
            "Epoch    4/20 H: tensor([137.7967, 165.6247, 163.1911, 177.7112, 126.3307]) Cost: 287.936096\n",
            "Epoch    5/20 H: tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]) Cost: 91.371071\n",
            "Epoch    6/20 H: tensor([148.1035, 178.0143, 175.3980, 191.0042, 135.7812]) Cost: 29.758249\n",
            "Epoch    7/20 H: tensor([150.1744, 180.5042, 177.8509, 193.6753, 137.6805]) Cost: 10.445267\n",
            "Epoch    8/20 H: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]) Cost: 4.391237\n",
            "Epoch    9/20 H: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]) Cost: 2.493121\n",
            "Epoch   10/20 H: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]) Cost: 1.897688\n",
            "Epoch   11/20 H: tensor([152.5485, 183.3609, 180.6640, 196.7389, 139.8602]) Cost: 1.710552\n",
            "Epoch   12/20 H: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]) Cost: 1.651416\n",
            "Epoch   13/20 H: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]) Cost: 1.632369\n",
            "Epoch   14/20 H: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]) Cost: 1.625924\n",
            "Epoch   15/20 H: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]) Cost: 1.623420\n",
            "Epoch   16/20 H: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]) Cost: 1.622152\n",
            "Epoch   17/20 H: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]) Cost: 1.621261\n",
            "Epoch   18/20 H: tensor([152.7999, 183.6688, 180.9644, 197.0661, 140.0963]) Cost: 1.620501\n",
            "Epoch   19/20 H: tensor([152.8014, 183.6715, 180.9665, 197.0686, 140.0985]) Cost: 1.619757\n",
            "Epoch   20/20 H: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.0999]) Cost: 1.619046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SPWmTNjYVFy",
        "colab_type": "text"
      },
      "source": [
        "## Use nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLAPH2CYYX5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultivariateRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3,1)    # 입력 차원 3, 출력 차원 1\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jc9wmcAZzJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "ae70a2d8-602e-4ee5-c123-908ddbb35eaf"
      },
      "source": [
        "# 모델 초기화\n",
        "model = MultivariateRegressionModel()\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr = 1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    # h(x) 계산\n",
        "    hypo = model(x_train)\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(hypo, y_train)\n",
        "    # h(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, cost.item()\n",
        "    ))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/20 Cost: 11805.096680\n",
            "Epoch    1/20 Cost: 3701.325684\n",
            "Epoch    2/20 Cost: 1161.223267\n",
            "Epoch    3/20 Cost: 365.035400\n",
            "Epoch    4/20 Cost: 115.472191\n",
            "Epoch    5/20 Cost: 37.247196\n",
            "Epoch    6/20 Cost: 12.727512\n",
            "Epoch    7/20 Cost: 5.041341\n",
            "Epoch    8/20 Cost: 2.631833\n",
            "Epoch    9/20 Cost: 1.876171\n",
            "Epoch   10/20 Cost: 1.638941\n",
            "Epoch   11/20 Cost: 1.564190\n",
            "Epoch   12/20 Cost: 1.540381\n",
            "Epoch   13/20 Cost: 1.532529\n",
            "Epoch   14/20 Cost: 1.529690\n",
            "Epoch   15/20 Cost: 1.528409\n",
            "Epoch   16/20 Cost: 1.527630\n",
            "Epoch   17/20 Cost: 1.526990\n",
            "Epoch   18/20 Cost: 1.526437\n",
            "Epoch   19/20 Cost: 1.525856\n",
            "Epoch   20/20 Cost: 1.525290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97bFDlqLgpY3",
        "colab_type": "text"
      },
      "source": [
        "## Mini-Batch GD\n",
        " DataLoader(dataset,batch_size=2,shuffle=True,)  \n",
        "    - batch_size : 각 mini batch의 크기, 통상적으로 2의 제곱수  \n",
        "    - shuffle : Epoch 마다 데이터 셋을 섞어서 순서 바꿈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s459omV2gk6p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c23542cd-1df0-4a03-e4c3-431d99b8dbc4"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.x_data = [[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]]\n",
        "        self.y_data = [[152], [185], [180], [196], [142]]\n",
        "    \n",
        "    def __len__(self):  # dataset의 총 data 수\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):     # index 입력 받을 시, 상응하는 데이터 반환\n",
        "        x = torch.FloatTensor(self.x_data[idx])\n",
        "        y = torch.FloatTensor(self.y_data[idx])\n",
        "        return x, y\n",
        "    \n",
        "dataset = CustomDataset()\n",
        "dataloader = DataLoader(dataset,batch_size=2,shuffle=True)\n",
        "\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    for batch_idx, samples in enumerate(dataloader):\n",
        "        x_train, y_train = samples\n",
        "        # h(x)\n",
        "        hypo = model(x_train)\n",
        "        # cost -> mse 방식\n",
        "        cost = F.mse_loss(hypo,y_train)\n",
        "        # cost 로 h(x) 개선\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print('Epoch {:4d}/{} Batch {}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, batch_idx+1, len(dataloader), hypo.squeeze().detach(), cost.item()\n",
        "        ))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/20 Batch 1/3 hypothesis: tensor([180.2531, 142.9367]) Cost: 0.470684\n",
            "Epoch    0/20 Batch 2/3 hypothesis: tensor([196.8991, 185.9913]) Cost: 0.895543\n",
            "Epoch    0/20 Batch 3/3 hypothesis: 149.28053283691406 Cost: 7.395502\n",
            "Epoch    1/20 Batch 1/3 hypothesis: tensor([180.6496, 186.6332]) Cost: 1.544689\n",
            "Epoch    1/20 Batch 2/3 hypothesis: tensor([142.8073, 149.7513]) Cost: 2.854131\n",
            "Epoch    1/20 Batch 3/3 hypothesis: 197.31605529785156 Cost: 1.732002\n",
            "Epoch    2/20 Batch 1/3 hypothesis: tensor([142.5072, 149.4253]) Cost: 3.443201\n",
            "Epoch    2/20 Batch 2/3 hypothesis: tensor([186.1096, 197.0290]) Cost: 1.145004\n",
            "Epoch    2/20 Batch 3/3 hypothesis: 179.5895538330078 Cost: 0.168466\n",
            "Epoch    3/20 Batch 1/3 hypothesis: tensor([179.7891, 196.6517]) Cost: 0.234626\n",
            "Epoch    3/20 Batch 2/3 hypothesis: tensor([142.4794, 185.6348]) Cost: 0.316393\n",
            "Epoch    3/20 Batch 3/3 hypothesis: 149.1889190673828 Cost: 7.902176\n",
            "Epoch    4/20 Batch 1/3 hypothesis: tensor([143.1799, 180.5753]) Cost: 0.861552\n",
            "Epoch    4/20 Batch 2/3 hypothesis: tensor([186.1866, 149.8594]) Cost: 2.995049\n",
            "Epoch    4/20 Batch 3/3 hypothesis: 197.27349853515625 Cost: 1.621799\n",
            "Epoch    5/20 Batch 1/3 hypothesis: tensor([149.4148, 179.6865]) Cost: 3.390756\n",
            "Epoch    5/20 Batch 2/3 hypothesis: tensor([197.2001, 142.9598]) Cost: 1.180781\n",
            "Epoch    5/20 Batch 3/3 hypothesis: 185.76031494140625 Cost: 0.578079\n",
            "Epoch    6/20 Batch 1/3 hypothesis: tensor([149.1910, 185.3795]) Cost: 4.017224\n",
            "Epoch    6/20 Batch 2/3 hypothesis: tensor([196.7753, 179.9034]) Cost: 0.305175\n",
            "Epoch    6/20 Batch 3/3 hypothesis: 142.51588439941406 Cost: 0.266137\n",
            "Epoch    7/20 Batch 1/3 hypothesis: tensor([149.2825, 179.5277]) Cost: 3.803929\n",
            "Epoch    7/20 Batch 2/3 hypothesis: tensor([186.1692, 197.0984]) Cost: 1.286764\n",
            "Epoch    7/20 Batch 3/3 hypothesis: 142.43685913085938 Cost: 0.190846\n",
            "Epoch    8/20 Batch 1/3 hypothesis: tensor([142.3094, 185.4145]) Cost: 0.133771\n",
            "Epoch    8/20 Batch 2/3 hypothesis: tensor([196.1143, 149.0885]) Cost: 4.245081\n",
            "Epoch    8/20 Batch 3/3 hypothesis: 179.8641357421875 Cost: 0.018459\n",
            "Epoch    9/20 Batch 1/3 hypothesis: tensor([196.8040, 185.8936]) Cost: 0.722471\n",
            "Epoch    9/20 Batch 2/3 hypothesis: tensor([149.2584, 142.3391]) Cost: 3.815799\n",
            "Epoch    9/20 Batch 3/3 hypothesis: 179.99610900878906 Cost: 0.000015\n",
            "Epoch   10/20 Batch 1/3 hypothesis: tensor([185.9614, 142.7260]) Cost: 0.725695\n",
            "Epoch   10/20 Batch 2/3 hypothesis: tensor([179.6244, 196.4708]) Cost: 0.181348\n",
            "Epoch   10/20 Batch 3/3 hypothesis: 149.33871459960938 Cost: 7.082440\n",
            "Epoch   11/20 Batch 1/3 hypothesis: tensor([180.6837, 186.6555]) Cost: 1.604012\n",
            "Epoch   11/20 Batch 2/3 hypothesis: tensor([142.8099, 196.9986]) Cost: 0.826488\n",
            "Epoch   11/20 Batch 3/3 hypothesis: 149.42605590820312 Cost: 6.625188\n",
            "Epoch   12/20 Batch 1/3 hypothesis: tensor([150.3195, 180.7496]) Cost: 1.693049\n",
            "Epoch   12/20 Batch 2/3 hypothesis: tensor([186.8853, 197.8727]) Cost: 3.530500\n",
            "Epoch   12/20 Batch 3/3 hypothesis: 142.68557739257812 Cost: 0.470016\n",
            "Epoch   13/20 Batch 1/3 hypothesis: tensor([142.4856, 149.4290]) Cost: 3.422841\n",
            "Epoch   13/20 Batch 2/3 hypothesis: tensor([197.0211, 180.1307]) Cost: 0.529817\n",
            "Epoch   13/20 Batch 3/3 hypothesis: 185.78395080566406 Cost: 0.614579\n",
            "Epoch   14/20 Batch 1/3 hypothesis: tensor([179.4421, 149.2170]) Cost: 4.028222\n",
            "Epoch   14/20 Batch 2/3 hypothesis: tensor([142.8355, 186.1078]) Cost: 0.962729\n",
            "Epoch   14/20 Batch 3/3 hypothesis: 196.5721893310547 Cost: 0.327401\n",
            "Epoch   15/20 Batch 1/3 hypothesis: tensor([196.2424, 149.1957]) Cost: 3.961352\n",
            "Epoch   15/20 Batch 2/3 hypothesis: tensor([179.9274, 185.8818]) Cost: 0.391438\n",
            "Epoch   15/20 Batch 3/3 hypothesis: 142.5079345703125 Cost: 0.257998\n",
            "Epoch   16/20 Batch 1/3 hypothesis: tensor([149.2986, 185.4847]) Cost: 3.766394\n",
            "Epoch   16/20 Batch 2/3 hypothesis: tensor([196.8472, 179.9716]) Cost: 0.359287\n",
            "Epoch   16/20 Batch 3/3 hypothesis: 142.5274200439453 Cost: 0.278172\n",
            "Epoch   17/20 Batch 1/3 hypothesis: tensor([179.5560, 142.3736]) Cost: 0.168356\n",
            "Epoch   17/20 Batch 2/3 hypothesis: tensor([185.5414, 149.3476]) Cost: 3.664076\n",
            "Epoch   17/20 Batch 3/3 hypothesis: 196.8829345703125 Cost: 0.779573\n",
            "Epoch   18/20 Batch 1/3 hypothesis: tensor([196.3740, 185.4835]) Cost: 0.186804\n",
            "Epoch   18/20 Batch 2/3 hypothesis: tensor([179.3192, 149.1165]) Cost: 4.389104\n",
            "Epoch   18/20 Batch 3/3 hypothesis: 142.7745819091797 Cost: 0.599977\n",
            "Epoch   19/20 Batch 1/3 hypothesis: tensor([196.6438, 149.5110]) Cost: 3.304813\n",
            "Epoch   19/20 Batch 2/3 hypothesis: tensor([186.0787, 142.8115]) Cost: 0.911116\n",
            "Epoch   19/20 Batch 3/3 hypothesis: 179.707275390625 Cost: 0.085688\n",
            "Epoch   20/20 Batch 1/3 hypothesis: tensor([196.7136, 149.5661]) Cost: 3.216454\n",
            "Epoch   20/20 Batch 2/3 hypothesis: tensor([180.1603, 142.8370]) Cost: 0.363169\n",
            "Epoch   20/20 Batch 3/3 hypothesis: 185.9131317138672 Cost: 0.833810\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}