{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab02_Gradient_Descent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaGTOnx98pq3",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Descent 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uufUS5D88NRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpVGe-6L-6Z7",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Descent 구현\n",
        "$$ cost(W) = \\frac{1}{m} \\sum^m_{i=1} \\left( Wx^{(i)} - y^{(i)} \\right)^2 $$\n",
        "$$ \\nabla W = \\frac{\\partial cost}{\\partial W} = \\frac{2}{m} \\sum^m_{i=1} \\left( Wx^{(i)} - y^{(i)} \\right)x^{(i)} $$\n",
        "\n",
        "$$ W := W - \\alpha \\nabla W $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdHTYrm18s3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "ad30ccf1-25e6-491e-fa08-c5dbb839a6ce"
      },
      "source": [
        "# 데이터 셋\n",
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[1],[2],[3]])\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1)\n",
        "lr = 0.1\n",
        "\n",
        "nb_epochs = 10\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # hypothesis 계산\n",
        "    hypo = x_train * W\n",
        "    \n",
        "    # cost gradient 계산\n",
        "    cost = torch.mean((hypo - y_train)**2)\n",
        "    gradient = torch.sum((W * x_train - y_train)*x_train)\n",
        "\n",
        "    print('Epoch {:4d}/{}, W: {:.3f}, Cost: {:.6f}'.format(epoch, nb_epochs, W.item(), cost.item()))\n",
        "\n",
        "    # cost gradient 로 H(x) 개선\n",
        "    W -= lr * gradient\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/10, W: 0.000, Cost: 4.666667\n",
            "Epoch    1/10, W: 1.400, Cost: 0.746666\n",
            "Epoch    2/10, W: 0.840, Cost: 0.119467\n",
            "Epoch    3/10, W: 1.064, Cost: 0.019115\n",
            "Epoch    4/10, W: 0.974, Cost: 0.003058\n",
            "Epoch    5/10, W: 1.010, Cost: 0.000489\n",
            "Epoch    6/10, W: 0.996, Cost: 0.000078\n",
            "Epoch    7/10, W: 1.002, Cost: 0.000013\n",
            "Epoch    8/10, W: 0.999, Cost: 0.000002\n",
            "Epoch    9/10, W: 1.000, Cost: 0.000000\n",
            "Epoch   10/10, W: 1.000, Cost: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asG5yhbq--NX",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Descent with optim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SryXzlsW_DWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "1e5b417d-2779-4f87-f300-95f8c9d4589b"
      },
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[1],[2],[3]])\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W], lr=0.15)\n",
        "\n",
        "nb_epochs = 10\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    #H(x) 계산\n",
        "    hypo = x_train * W\n",
        "    \n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypo - y_train) ** 2)\n",
        "\n",
        "    print(\"Epoch {:4d}/{}, W: {:.3f}, cost: {:.6f}\".format(epoch,nb_epochs,W.item(),cost.item()))\n",
        "\n",
        "    #cost로 H(x) 개선\n",
        "    optimizer.zero_grad()   # gradient 0 으로 초기화\n",
        "    cost.backward()         # gradient 계산\n",
        "    optimizer.step()        # gradient 개선"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/10, W: 0.000, cost: 4.666667\n",
            "Epoch    1/10, W: 1.400, cost: 0.746667\n",
            "Epoch    2/10, W: 0.840, cost: 0.119467\n",
            "Epoch    3/10, W: 1.064, cost: 0.019115\n",
            "Epoch    4/10, W: 0.974, cost: 0.003058\n",
            "Epoch    5/10, W: 1.010, cost: 0.000489\n",
            "Epoch    6/10, W: 0.996, cost: 0.000078\n",
            "Epoch    7/10, W: 1.002, cost: 0.000013\n",
            "Epoch    8/10, W: 0.999, cost: 0.000002\n",
            "Epoch    9/10, W: 1.000, cost: 0.000000\n",
            "Epoch   10/10, W: 1.000, cost: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}